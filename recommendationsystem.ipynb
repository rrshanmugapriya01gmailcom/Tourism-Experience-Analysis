{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ebcbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Hybrid Recommendations for user '70456' based on attraction 'Sacred Monkey Forest Sanctuary':\n",
      "👉 Tegalalang Rice Terrace\n",
      "👉 Kuta Beach - Bali\n",
      "👉 Uluwatu Temple\n",
      "👉 Seminyak Beach\n",
      "👉 Tegenungan Waterfall\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(r\"C:\\Tourism\\Tourism_preprocessed_data.csv\")\n",
    "\n",
    "# ==============================\n",
    "# STEP 1: CONTENT-BASED SECTION\n",
    "# ==============================\n",
    "\n",
    "# Numeric features for content-based filtering\n",
    "numeric_cols = [\n",
    "    \"AttractionPopularity\", \"IsTopAttraction\", \"RegionPopularity\",\n",
    "    \"IsCulturalAttraction\", \"CityAvgRating\", \"CountryAvgRating\",\n",
    "    \"AttractionRatingStd\", \"AttractionAvgRating\", \"AttractionRatingDeviation\",\n",
    "    \"AttractionSeasonality\", \"PopularityRatio\"\n",
    "]\n",
    "\n",
    "# Ensure numeric format and fill NaNs\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "# Group by attraction and average the features\n",
    "attraction_features = df.groupby(\"Attraction\")[numeric_cols].mean().reset_index()\n",
    "attraction_features[numeric_cols] = attraction_features[numeric_cols].fillna(0)\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "normalized = scaler.fit_transform(attraction_features[numeric_cols])\n",
    "similarity_matrix = cosine_similarity(normalized)\n",
    "\n",
    "# Attraction list\n",
    "attraction_names = attraction_features[\"Attraction\"].tolist()\n",
    "\n",
    "# Content-based recommendation function\n",
    "def content_based_recommendations(attraction_name, top_n=5):\n",
    "    if attraction_name not in attraction_names:\n",
    "        return []\n",
    "    idx = attraction_names.index(attraction_name)\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, score in similarity_scores[1:top_n+1]]\n",
    "    return [attraction_names[i] for i in top_indices]\n",
    "\n",
    "# ==================================\n",
    "# STEP 2: COLLABORATIVE FILTERING\n",
    "# ==================================\n",
    "\n",
    "# Create user-item matrix from ratings\n",
    "user_item_matrix = df.pivot_table(index=\"UserId\", columns=\"Attraction\", values=\"Rating\")\n",
    "user_item_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Compute similarity between attractions based on ratings\n",
    "item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
    "\n",
    "# Collaborative recommendation function\n",
    "def collaborative_recommendations(user_id, top_n=5):\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return []\n",
    "    \n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    scores = item_similarity_df.dot(user_ratings).div(item_similarity_df.sum(axis=1))\n",
    "    scores = scores.sort_values(ascending=False)\n",
    "    \n",
    "    already_visited = user_ratings[user_ratings > 0].index.tolist()\n",
    "    recommended = [attr for attr in scores.index if attr not in already_visited]\n",
    "    \n",
    "    return recommended[:top_n]\n",
    "\n",
    "# ================================\n",
    "# STEP 3: HYBRID RECOMMENDATIONS\n",
    "# ================================\n",
    "\n",
    "def hybrid_recommendations(user_id, attraction_name, top_n=5):\n",
    "    content_recs = set(content_based_recommendations(attraction_name, top_n=10))\n",
    "    collaborative_recs = set(collaborative_recommendations(user_id, top_n=10))\n",
    "\n",
    "    # Combine both\n",
    "    hybrid = list(content_recs.intersection(collaborative_recs))\n",
    "    \n",
    "    # Fallback: if no common recommendations, use union\n",
    "    if not hybrid:\n",
    "        hybrid = list(content_recs.union(collaborative_recs))\n",
    "    \n",
    "    return hybrid[:top_n]\n",
    "\n",
    "# ===============================\n",
    "# EXAMPLE USAGE\n",
    "# ===============================\n",
    "\n",
    "sample_user = df[\"UserId\"].iloc[0]  # Replace with real user if needed\n",
    "sample_attraction = df[\"Attraction\"].iloc[0]  # Replace with real attraction\n",
    "\n",
    "print(f\"\\n🔁 Hybrid Recommendations for user '{sample_user}' based on attraction '{sample_attraction}':\")\n",
    "for rec in hybrid_recommendations(user_id=sample_user, attraction_name=sample_attraction):\n",
    "    print(\"👉\", rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dec23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    hits = len(set(recommended_k) & set(relevant))\n",
    "    return hits / len(relevant) if relevant else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cdf43ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 70456 liked these attractions: {'Sacred Monkey Forest Sanctuary'}\n",
      "Hybrid recommendations: ['Merapi Volcano', 'Tegalalang Rice Terrace', 'Tegenungan Waterfall', 'Seminyak Beach', 'Uluwatu Temple', 'Sanur Beach', 'Kuta Beach - Bali', 'Nusa Dua Beach', 'Tanah Lot Temple', 'Waterbom Bali']\n"
     ]
    }
   ],
   "source": [
    "liked = set(df[(df['UserId'] == sample_user) & (df['Rating'] >= 4)]['Attraction'])\n",
    "print(f\"User {sample_user} liked these attractions:\", liked)\n",
    "\n",
    "top_attraction = df[df['UserId'] == sample_user].sort_values(by='Rating', ascending=False)['Attraction'].iloc[0]\n",
    "recs = hybrid_recommendations(sample_user, top_attraction, top_n=10)\n",
    "print(\"Hybrid recommendations:\", recs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c25ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    hit_count = sum([1 for r in recommended_k if r in relevant_set])\n",
    "    return hit_count / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    recommended_k = recommended[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    hit_count = sum([1 for r in recommended_k if r in relevant_set])\n",
    "    return hit_count / len(relevant_set) if len(relevant_set) > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc54a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendations_weighted(user_id, attraction_name, top_n=10, alpha=0.5):\n",
    "    # Content-based scores (similarity to given attraction)\n",
    "    if attraction_name not in attraction_names:\n",
    "        return []\n",
    "    idx = attraction_names.index(attraction_name)\n",
    "    content_scores = similarity_matrix[idx]\n",
    "    \n",
    "    # Collaborative scores (weighted sum of item similarity and user ratings)\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return []\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    collaborative_scores = item_similarity_df.dot(user_ratings).div(item_similarity_df.sum(axis=1))\n",
    "    \n",
    "    # Normalize both scores between 0 and 1\n",
    "    content_scores_norm = (content_scores - content_scores.min()) / (content_scores.max() - content_scores.min())\n",
    "    collaborative_scores_norm = (collaborative_scores - collaborative_scores.min()) / (collaborative_scores.max() - collaborative_scores.min())\n",
    "    \n",
    "    # Align collaborative scores order with content scores attractions\n",
    "    collaborative_scores_norm = collaborative_scores_norm.reindex(attraction_names).fillna(0).values\n",
    "    \n",
    "    # Combine scores with weight alpha\n",
    "    hybrid_scores = alpha * content_scores_norm + (1 - alpha) * collaborative_scores_norm\n",
    "    \n",
    "    # Remove the queried attraction itself\n",
    "    hybrid_scores[idx] = -1\n",
    "    \n",
    "    # Get top_n recommendations\n",
    "    top_indices = np.argsort(hybrid_scores)[::-1][:top_n]\n",
    "    recommendations = [attraction_names[i] for i in top_indices]\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa7742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Precision@5: 0.129\n",
      "Avg Recall@5: 0.216\n"
     ]
    }
   ],
   "source": [
    "# Sample test users (you can filter or sample as needed)\n",
    "test_users = df['UserId'].unique()[:20]\n",
    "\n",
    "k = 5\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for user in test_users:\n",
    "    user_data = df[df['UserId'] == user]\n",
    "    relevant_attractions = user_data[user_data['Rating'] >= 4]['Attraction'].tolist()  # consider rating >=4 as relevant\n",
    "    \n",
    "    if len(relevant_attractions) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Pick a random attraction from user's liked list as seed\n",
    "    seed_attraction = relevant_attractions[0]\n",
    "    \n",
    "    recommended = hybrid_recommendations_weighted(user, seed_attraction, top_n=k, alpha=0.5)\n",
    "    \n",
    "    prec = precision_at_k(recommended, relevant_attractions, k)\n",
    "    rec = recall_at_k(recommended, relevant_attractions, k)\n",
    "    \n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "print(f\"Avg Precision@{k}: {np.mean(precisions):.3f}\")\n",
    "print(f\"Avg Recall@{k}: {np.mean(recalls):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f357f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ef6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_objects = {\n",
    "    \"attraction_names\": attraction_names,\n",
    "    \"similarity_matrix\": similarity_matrix,\n",
    "    \"user_item_matrix\": user_item_matrix,\n",
    "    \"item_similarity_df\": item_similarity_df,\n",
    "    \"scaler\": scaler\n",
    "}\n",
    "\n",
    "with open(r\"C:\\Tourism\\hybrid_recommender_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_objects, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
